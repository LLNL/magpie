# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master            spark://master:7077
# spark.eventLog.enabled  true
# spark.eventLog.dir      hdfs://namenode:8021/directory
# spark.serializer        org.apache.spark.serializer.KryoSerializer

spark.master		         SPARKMASTER

# Depending on version, magpie-setup-spark will comment out
# spark.shuffle.file.buffer.kb or spark.shuffle.file.buffer

spark.shuffle.file.buffer.kb     SPARKSHUFFLEFILEBUFFERKB
spark.shuffle.file.buffer        SPARKSHUFFLEFILEBUFFER

spark.shuffle.consolidateFiles   SPARKSHUFFLECONSOLIDATEFILES

spark.default.parallelism        SPARKDEFAULTPARALLELISM

spark.executor.memory            SPARKEXECUTORMEMORYm
spark.executor.extraClassPath    SPARKEXECUTOREXTRACLASSPATH

spark.driver.extraClassPath      SPARKDRIVEREXTRACLASSPATH

spark.ui.port                    SPARKUIPORT

# magpie-setup-spark will comment out spark.akka.threads on versions
# not supported

spark.akka.threads               SPARKAKKATHREADS

# Depending on version, magpie-setup-spark will comment out
# spark.storage.memoryFraction & spark.shuffle.memoryFraction
# OR
# spark.memory.fraction & spark.memory.storageFraction

spark.storage.memoryFraction     SPARKSTORAGEMEMORYFRACTION
spark.shuffle.memoryFraction     SPARKSHUFFLEMEMORYFRACTION

spark.memory.fraction            SPARKMEMORYFRACTION
spark.memory.storageFraction     SPARKMEMORYSTORAGEFRACTION

spark.deploy.spreadOut           SPARKDEPLOYSPREADOUT

spark.authenticate               true
spark.authenticate.secret        SPARKAUTHENTICATESECRET

spark.driver.extraJavaOptions    EXTRASPARKJAVAOPTS
spark.executor.extraJavaOptions  EXTRASPARKJAVAOPTS

# For ease, we treat all timeouts with one config

spark.files.fetchTimeout                SPARKNETWORKTIMEOUTSECSs
spark.network.timeout                   SPARKNETWORKTIMEOUTSECSs
spark.rpc.askTimeout                    SPARKNETWORKTIMEOUTSECSs
spark.rpc.lookupTimeout                 SPARKNETWORKTIMEOUTSECSs
spark.core.connection.ack.wait.timeout  SPARKNETWORKTIMEOUTSECSs
spark.shuffle.registration.timeout      SPARKNETWORKTIMEOUTMS
spark.network.auth.rpcTimeout           SPARKNETWORKTIMEOUTSECSs
spark.shuffle.sasl.timeout              SPARKNETWORKTIMEOUTSECSs

spark.rdd.compress                      SPARKRDDCOMPRESS
spark.io.compression.codec              SPARKIOCOMPRESSIONCODEC

# Sparklyr needs to know the catalogImplementation in order to read
# the HIVE tables
# spark.sql.catalogImplementation hive

@YARN@
