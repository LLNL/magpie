diff -pruN spark-1.2.0-bin-hadoop2.4-orig/sbin/spark-daemons.sh spark-1.2.0-bin-hadoop2.4/sbin/spark-daemons.sh
--- spark-1.2.0-bin-hadoop2.4-orig/sbin/spark-daemons.sh	2014-12-10 03:00:25.000000000 -0800
+++ spark-1.2.0-bin-hadoop2.4/sbin/spark-daemons.sh	2015-01-20 11:13:26.292158000 -0800
@@ -30,6 +30,24 @@ fi
 sbin=`dirname "$0"`
 sbin=`cd "$sbin"; pwd`
 
+# Check if --config is passed as an argument. It is an optional parameter.
+# Exit if the argument is not a directory.
+
+if [ "$1" == "--config" ]
+then
+  shift
+  conf_dir=$1
+  if [ ! -d "$conf_dir" ]
+  then
+    echo "ERROR : $conf_dir is not a directory"
+    echo $usage
+    exit 1
+  else
+    export SPARK_CONF_DIR=$conf_dir
+  fi
+  shift
+fi
+
 . "$sbin/spark-config.sh"
 
-exec "$sbin/slaves.sh" cd "$SPARK_HOME" \; "$sbin/spark-daemon.sh" "$@"
+exec "$sbin/slaves.sh" --config $SPARK_CONF_DIR cd "$SPARK_HOME" \; "$sbin/spark-daemon.sh" --config $SPARK_CONF_DIR "$@"
diff -pruN spark-1.2.0-bin-hadoop2.4-orig/sbin/start-slave.sh spark-1.2.0-bin-hadoop2.4/sbin/start-slave.sh
--- spark-1.2.0-bin-hadoop2.4-orig/sbin/start-slave.sh	2014-12-10 03:00:25.000000000 -0800
+++ spark-1.2.0-bin-hadoop2.4/sbin/start-slave.sh	2015-01-20 11:13:26.314138000 -0800
@@ -23,4 +23,27 @@
 sbin="`dirname "$0"`"
 sbin="`cd "$sbin"; pwd`"
 
-"$sbin"/spark-daemon.sh start org.apache.spark.deploy.worker.Worker "$@"
+# Check if --config is passed as an argument. It is an optional parameter.
+# Exit if the argument is not a directory.
+
+if [ "$1" == "--config" ]
+then
+  shift
+  conf_dir=$1
+  if [ ! -d "$conf_dir" ]
+  then
+    echo "ERROR : $conf_dir is not a directory"
+    echo $usage
+    exit 1
+  else
+    export SPARK_CONF_DIR=$conf_dir
+  fi
+  shift
+fi
+
+if [ "${SPARK_CONF_DIR}X" != "X" ]
+then
+    "$sbin"/spark-daemon.sh --config $SPARK_CONF_DIR start org.apache.spark.deploy.worker.Worker "$@"
+else
+    "$sbin"/spark-daemon.sh start org.apache.spark.deploy.worker.Worker "$@"
+fi
diff -pruN spark-1.2.0-bin-hadoop2.4-orig/sbin/start-slaves.sh spark-1.2.0-bin-hadoop2.4/sbin/start-slaves.sh
--- spark-1.2.0-bin-hadoop2.4-orig/sbin/start-slaves.sh	2014-12-10 03:00:25.000000000 -0800
+++ spark-1.2.0-bin-hadoop2.4/sbin/start-slaves.sh	2015-01-20 11:34:50.658506000 -0800
@@ -58,12 +58,12 @@ fi
 
 # Launch the slaves
 if [ "$SPARK_WORKER_INSTANCES" = "" ]; then
-  exec "$sbin/slaves.sh" cd "$SPARK_HOME" \; "$sbin/start-slave.sh" 1 "spark://$SPARK_MASTER_IP:$SPARK_MASTER_PORT"
+  exec "$sbin/slaves.sh" --config $SPARK_CONF_DIR cd "$SPARK_HOME" \; "$sbin/start-slave.sh" --config $SPARK_CONF_DIR 1 "spark://$SPARK_MASTER_IP:$SPARK_MASTER_PORT"
 else
   if [ "$SPARK_WORKER_WEBUI_PORT" = "" ]; then
     SPARK_WORKER_WEBUI_PORT=8081
   fi
   for ((i=0; i<$SPARK_WORKER_INSTANCES; i++)); do
-    "$sbin/slaves.sh" cd "$SPARK_HOME" \; "$sbin/start-slave.sh" $(( $i + 1 ))  "spark://$SPARK_MASTER_IP:$SPARK_MASTER_PORT" --webui-port $(( $SPARK_WORKER_WEBUI_PORT + $i ))
+    "$sbin/slaves.sh" --config $SPARK_CONF_DIR cd "$SPARK_HOME" \; "$sbin/start-slave.sh" --config $SPARK_CONF_DIR $(( $i + 1 ))  "spark://$SPARK_MASTER_IP:$SPARK_MASTER_PORT" --webui-port $(( $SPARK_WORKER_WEBUI_PORT + $i ))
   done
 fi
diff -pruN spark-1.2.0-bin-hadoop2.4-orig/sbin/stop-slaves.sh spark-1.2.0-bin-hadoop2.4/sbin/stop-slaves.sh
--- spark-1.2.0-bin-hadoop2.4-orig/sbin/stop-slaves.sh	2014-12-10 03:00:25.000000000 -0800
+++ spark-1.2.0-bin-hadoop2.4/sbin/stop-slaves.sh	2015-01-20 11:13:26.356097000 -0800
@@ -30,9 +30,9 @@ if [ -e "$sbin"/../tachyon/bin/tachyon ]
 fi
 
 if [ "$SPARK_WORKER_INSTANCES" = "" ]; then
-  "$sbin"/spark-daemons.sh stop org.apache.spark.deploy.worker.Worker 1
+  "$sbin"/spark-daemons.sh --config $SPARK_CONF_DIR stop org.apache.spark.deploy.worker.Worker 1
 else
   for ((i=0; i<$SPARK_WORKER_INSTANCES; i++)); do
-    "$sbin"/spark-daemons.sh stop org.apache.spark.deploy.worker.Worker $(( $i + 1 ))
+    "$sbin"/spark-daemons.sh --config $SPARK_CONF_DIR stop org.apache.spark.deploy.worker.Worker $(( $i + 1 ))
   done
 fi
