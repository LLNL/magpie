#!/bin/bash
#############################################################################
#  Copyright (C) 2013 Lawrence Livermore National Security, LLC.
#  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
#  Written by Albert Chu <chu11@llnl.gov>
#  LLNL-CODE-644248
#  
#  This file is part of Magpie, scripts for running Hadoop on
#  traditional HPC systems.  For details, see <URL>.
#  
#  Magpie is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Magpie is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Magpie.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# This script is the core processing script for setting up daemons and
# running jobs.  For the most part, it shouldn't be editted.  See
# job submission files for configuration details.

source ${MAGPIE_SCRIPTS_HOME}/magpie-submission-convert
source ${MAGPIE_SCRIPTS_HOME}/magpie-common-exports
source ${MAGPIE_SCRIPTS_HOME}/magpie-common-functions

if ! Magpie_am_I_master
then
    exit 0
fi

# Output some general info
echo "*******************************************************"
echo "* Magpie General Job Info"
echo "*"
echo "* Job Nodelist: ${MAGPIE_NODELIST}"
echo "* Job Nodecount: ${MAGPIE_NODE_COUNT}"
echo "* Job Timelimit in Minutes: ${MAGPIE_TIMELIMIT_MINUTES}"
echo "* Job Name: ${MAGPIE_JOB_NAME}"
echo "* Job ID: ${MAGPIE_JOB_ID}"
echo "*"
echo "*******************************************************"

if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
then
    if [ -f "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}" ]
    then
	rm -f ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi
    
    touch ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    chmod 700 ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

    echo "#!${SHELL}" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

    echo "# Common environment variables for Job = ${MAGPIE_JOB_NAME}, Job ID = ${MAGPIE_JOB_ID}" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

    echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    if [ "${JAVA_HOME}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv JAVA_HOME \"${JAVA_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export JAVA_HOME=\"${JAVA_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi
fi

#
# Setup ZooKeeper
#

totalsleepwait=0

# Zookeeper setup comes first, as other things like Hbase & Storm require it

if [ "${ZOOKEEPER_SETUP}" == "yes" ]
then
    if [ "${ZOOKEEPER_MODE}" != "setuponly" ]
    then
	echo "Starting Zookeeper"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-zookeeper.sh start

        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${ZOOKEEPER_REPLICATION_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Zookeeper daemons to setup"
	sleep ${sleepwait}
	totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Zookeeper Information"
    echo "*"
    if [ "${ZOOKEEPER_MODE}" == "setuponly" ]
    then
 	echo "* To setup, you probably want to run:" 
	echo "*   ${magpieremotecmd} ${ZOOKEEPER_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv ZOOCFGDIR \"${ZOOKEEPER_CONF_DIR}\""
	else
	    echo "*   export ZOOCFGDIR=\"${ZOOKEEPER_CONF_DIR}\""
	fi
	echo "*   cd $MAGPIE_SCRIPTS_HOME"
	echo "*   bin/magpie-zookeeper.sh start"
	echo "*" 
    fi
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${ZOOKEEPER_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv ZOOCFGDIR \"${ZOOKEEPER_CONF_DIR}\""
    else
	echo "*   export ZOOCFGDIR=\"${ZOOKEEPER_CONF_DIR}\""
    fi
    echo "*   cd $MAGPIE_SCRIPTS_HOME"
    echo "*   bin/magpie-zookeeper.sh stop"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv ZOOKEEPER_HOME \"${ZOOKEEPER_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export ZOOKEEPER_HOME=\"${ZOOKEEPER_HOME}\""
    fi
    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	echo "*"
	echo "* If running interactively, sourcing"
	echo "*"
	echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
	echo "*"
	echo "* will set most common environment variables for your job."
    fi
    echo "*" 
    echo "*******************************************************"

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv ZOOKEEPER_HOME \"${ZOOKEEPER_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv ZOOCFGDIR \"${ZOOKEEPER_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv ZOOKEEPER_CONF_DIR \"${ZOOKEEPER_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv ZOOKEEPER_LOG_DIR \"${ZOOKEEPER_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export ZOOKEEPER_HOME=\"${ZOOKEEPER_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export ZOOCFGDIR=\"${ZOOKEEPER_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export ZOOKEEPER_CONF_DIR=\"${ZOOKEEPER_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export ZOOKEEPER_LOG_DIR=\"${ZOOKEEPER_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi
    
    # Nothing to check for Zookeeper, setup always completes
    zookeepersetupcomplete=1
else
    zookeepersetupcomplete=1
fi

#
# Setup Hadoop
#

if [ "${HADOOP_SETUP}" == "yes" ]
then
    cd ${HADOOP_HOME}

    if [ ${HADOOP_MODE} != "setuponly" ]
    then
	echo "Starting hadoop"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
	then
	    if [ "${MAGPIE_JOB_TYPE}" == "hadoop" ] && [ "${HADOOP_MODE}" == "upgradehdfs" ]
	    then
		startdfsoptions="-upgrade"
	    fi

	    ${hadoopsetupscriptprefix}/start-dfs.sh ${startdfsoptions}
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${hadoopsetupscriptprefix}/start-mapred.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${hadoopsetupscriptprefix}/start-yarn.sh
	fi
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${HADOOP_SLAVE_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allows Hadoop daemons to setup"
	sleep ${sleepwait}
	totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Hadoop Information"
    echo "*"
    echo "* You can view your Hadoop status by launching a web browser and pointing to ..."
    echo "*"
    if [ ${HADOOP_SETUP_TYPE}  == "MR1" ]
    then
	echo "* Jobtracker: http://${HADOOP_MASTER_NODE}:${MAPRED_JOB_TRACKER_HTTPADDRESS}"
	echo "*"
    elif [ ${HADOOP_SETUP_TYPE}  == "MR2" ]
    then
	echo "* Yarn Resource Manager: http://${HADOOP_MASTER_NODE}:${YARN_RESOURCEMANAGER_WEBAPP_ADDRESS}"
	echo "*"
	echo "* Job History Server: http://${HADOOP_MASTER_NODE}:${HADOOP_JOBHISTORYSERVER_WEBAPP_ADDRESS}"
	echo "*"
    fi
    if [ ${HADOOP_FILESYSTEM_MODE} == "hdfs" ] \
	|| [ ${HADOOP_FILESYSTEM_MODE} == "hdfsoverlustre" ] \
	|| [ ${HADOOP_FILESYSTEM_MODE} == "hdfsovernetworkfs" ]
    then
	if [ "${HDFS_FEDERATION_NAMENODE_COUNT}" -gt 1 ]
	then
	    for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
	    do
	        # First namenode is based on master
		if [ "${i}" == "1" ]
		then
		    federationnamenodehost="${HADOOP_MASTER_NODE}"
		else
		    numline=`expr ${i} - 1`
		    federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
		fi
	    	echo "* HDFS Namenode ${i}: http://${federationnamenodehost}:${HADOOP_HDFS_NAMENODE_HTTPADDRESS}"
	    done
	else
	    echo "* HDFS Namenode: http://${HADOOP_MASTER_NODE}:${HADOOP_HDFS_NAMENODE_HTTPADDRESS}"
	fi
	echo "* HDFS DataNode: http://<DATANODE>:${HADOOP_HDFS_DATANODE_HTTPADDRESS}"
	echo "*"
	echo "* HDFS can be accessed directly at:"
	echo "*"
	if [ "${HDFS_FEDERATION_NAMENODE_COUNT}" -gt 1 ]
	then
	    for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
	    do
	        # First namenode is based on master
		if [ "${i}" == "1" ]
		then
		    federationnamenodehost="${HADOOP_MASTER_NODE}"
		else
		    numline=`expr ${i} - 1`
		    federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
		fi
	    	echo "* hdfs://${federationnamenodehost}:${HADOOP_HDFS_NAMENODE_ADDRESS}"
	    done
	else
	    echo "*   hdfs://${HADOOP_MASTER_NODE}:${HADOOP_HDFS_NAMENODE_ADDRESS}" 
	fi
	echo "*" 
    fi
    echo "*" 
    echo "* To access Hadoop directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${HADOOP_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
    else
	echo "*   export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
    fi
    echo "*   cd $HADOOP_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to interact with the Hadoop filesystem:"
    echo "*" 
    echo "*   ${hadoopcmdprefix}/hadoop fs ..."
    echo "*" 
    echo "* To launch jobs you'll want to:"
    echo "*" 
    echo "*   ${hadoopcmdprefix}/hadoop jar ..."
    echo "*" 
    if [ "${PIG_SETUP}" == "yes" ] && [ "${PIG_MODE}" == "interactive" ]
    then
	echo "*"
	echo "* To run pig scripts:"
	echo "*"
	echo "* cd $PIG_HOME"
	echo "* ${pigcmdprefix}/pig ..."
    fi
    if [ "${HADOOP_MODE}" == "setuponly" ]
    then
	echo "*" 
 	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${HADOOP_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
	else
	    echo "*   export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
	fi
	echo "*   cd $HADOOP_HOME"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-dfs.sh" 
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-mapred.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-yarn.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-jobhistoryserver.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh start historyserver"
	fi
    fi

    echo "*" 
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${HADOOP_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
    else
	echo "*   export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
    fi
    echo "*   cd $HADOOP_HOME"
    if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-mapred.sh"
    fi
    if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-yarn.sh"
    fi
    if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-dfs.sh"
    fi
    if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-jobhistoryserver.sh"
    fi
    if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh stop historyserver"
    fi
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv HADOOP_HOME \"${HADOOP_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export HADOOP_HOME=\"${HADOOP_HOME}\""
    fi
    if [ "${PIG_SETUP}" == "yes" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv PIG_HOME \"${PIG_HOME}\""
	    echo "*   setenv PIG_CONF_DIR \"${PIG_CONF_DIR}\""
	else
	    echo "*   export PIG_HOME=\"${PIG_HOME}\""
	    echo "*   export PIG_CONF_DIR=\"${PIG_CONF_DIR}\""
	fi
    fi

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	echo "*"
	echo "* If running interactively, sourcing"
	echo "*"
	echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
	echo "*"
	echo "* will set most common environment variables for your job."
    fi
    echo "*" 
    echo "*******************************************************"

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv HADOOP_HOME \"${HADOOP_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_LOG_DIR \"${HADOOP_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_MASTER_NODE \"${HADOOP_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_SLAVE_COUNT \"${HADOOP_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_SLAVE_CORE_COUNT \"${HADOOP_SLAVE_CORE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_NAMENODE \"${HADOOP_NAMENODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HADOOP_NAMENODE_PORT \"${HADOOP_NAMENODE_PORT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export HADOOP_HOME=\"${HADOOP_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_LOG_DIR=\"${HADOOP_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_MASTER_NODE=\"${HADOOP_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_SLAVE_COUNT=\"${HADOOP_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_SLAVE_CORE_COUNT=\"${HADOOP_SLAVE_CORE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_NAMENODE=\"${HADOOP_NAMENODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HADOOP_NAMENODE_PORT=\"${HADOOP_NAMENODE_PORT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}

	if [ "${PIG_SETUP}" == "yes" ]
	then
	    if echo $SHELL | grep -q csh
	    then
		echo "setenv PIG_HOME \"${PIG_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
		echo "setenv PIG_CONF_DIR \"${PIG_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    else
		echo "export PIG_HOME=\"${PIG_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
		echo "export PIG_CONF_DIR=\"${PIG_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    fi
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi

    # Ensure namenode isn't in safe mode.
    #
    # We do not use "-safemode wait", b/c we want to inform the user
    # as we're waiting.
    if [ ${HADOOP_MODE} != "setuponly" ] \
	&& ([ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ])
    then
	namenodemaxwaitseconds=`expr ${MAGPIE_STARTUP_TIME} \* 60 - ${totalsleepwait}`

	if [ "${namenodemaxwaitseconds}" -lt 30 ]
	then
	    namenodemaxwaitseconds=30
	fi

	namenodemaxwaittimes=`expr ${namenodemaxwaitseconds} \/ 30`
	
	cd ${HADOOP_HOME}

	exittedsafemode=0

	for ((i = 1; i <= ${namenodemaxwaittimes}; i++)); do
	    
	    if [ "${HDFS_FEDERATION_NAMENODE_COUNT}" -gt 1 ]
	    then
		exittedsafemodeflag=1

		for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
		do
		     
	            # First namenode is based on master
		    if [ "${i}" == "1" ]
		    then
			federationnamenodehost="${HADOOP_MASTER_NODE}"
		    else
			numline=`expr ${i} - 1`
			federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
		    fi

		    ${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${HADOOP_HDFS_NAMENODE_ADDRESS} -safemode get 2>&1 | grep -q -i "off"
		    if [ $? -ne 0 ]
		    then
			exittedsafemodeflag=0
		    fi
		done

		if [ "${exittedsafemodeflag}" == "1" ]
		then
		    exittedsafemode=1
		    break
		fi
	    else
		${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode get 2>&1 | grep -q -i "off"
		if [ $? -eq 0 ]
		then
		    exittedsafemode=1
		    break
		fi
	    fi

	    echo "Waiting 30 more seconds for namenode to exit safe mode"
	    sleep 30
	done
	
	if [ "${exittedsafemode}" == "0" ]
	then
	    echo "Namenode never exited safe mode, setup problem or maybe need to increase MAGPIE_STARTUP_TIME"
	    hadoopsetupcomplete=0
	else
	    hadoopsetupcomplete=1
	fi
    else
	hadoopsetupcomplete=1
    fi

    # Setup job history server after namenode comes up, it may need to
    # write/create in HDFS
    if [ ${HADOOP_MODE} != "setuponly" ] && [ "${hadoopsetupcomplete}" == "1" ]
    then
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${hadoopsetupscriptprefix}/start-jobhistoryserver.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh start historyserver
	fi
    fi
else
    hadoopsetupcomplete=1
fi

#
# Setup Hbase
#

if [ "${HBASE_SETUP}" == "yes" ]
then
    cd ${HBASE_HOME}

    if [ ${HBASE_MODE} != "setuponly" ] && [ "${hadoopsetupcomplete}" == "1" ]
    then
	echo "Starting hbase"
	${hbasesetupscriptprefix}/start-hbase.sh
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${HBASE_REGIONSERVER_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Hbase daemons to setup"
	sleep ${sleepwait}
	totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Hbase Information"
    echo "*"
    echo "* You can view your Hbase status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Hbase Master: http://${HBASE_MASTER_NODE}:${HBASE_MASTER_INFO_PORT}"
    echo "* Hbase RegionServer: http://<REGIONSERVER>:${HBASE_REGIONSERVER_INFO_PORT}"
    echo "*" 
    echo "* To access Hbase directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${HBASE_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv HBASE_CONF_DIR \"${HBASE_CONF_DIR}\""
    else
	echo "*   export HBASE_CONF_DIR=\"${HBASE_CONF_DIR}\""
    fi
    echo "*   cd $HBASE_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to interact in the Hbase shell :"
    echo "*" 
    echo "*   ${hbasecmdprefix}/hbase shell"

    if [ "${HBASE_MODE}" == "setuponly" ]
    then
	echo "*" 
	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${HBASE_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv HBASE_CONF_DIR \"${HBASE_CONF_DIR}\""
	else
	    echo "*   export HBASE_CONF_DIR=\"${HBASE_CONF_DIR}\""
	fi
	echo "*   cd $HBASE_HOME"
	echo "*   ${hbasesetupscriptprefix}/start-hbase.sh" 
    fi

    echo "*" 
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${HBASE_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv HBASE_CONF_DIR \"${HBASE_CONF_DIR}\""
    else
	echo "*   export HBASE_CONF_DIR=\"${HBASE_CONF_DIR}\""
    fi
    echo "*   cd $HBASE_HOME"
    echo "*   ${hbasesetupscriptprefix}/stop-hbase.sh"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv HBASE_HOME \"${HBASE_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export HBASE_HOME=\"${HBASE_HOME}\""
    fi

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	echo "*"
	echo "* If running interactively, sourcing"
	echo "*"
	echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
	echo "*"
	echo "* will set most common environment variables for your job."
    fi
    echo "*" 
    echo "*******************************************************"

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv HBASE_HOME \"${HBASE_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HBASE_CONF_DIR \"${HBASE_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HBASE_LOG_DIR \"${HBASE_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HBASE_MASTER_NODE \"${HBASE_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv HBASE_REGIONSERVER_COUNT \"${HBASE_REGIONSERVER_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export HBASE_HOME=\"${HBASE_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HBASE_CONF_DIR=\"${HBASE_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HBASE_LOG_DIR=\"${HBASE_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HBASE_MASTER_NODE=\"${HBASE_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export HBASE_REGIONSERVER_COUNT=\"${HBASE_REGIONSERVER_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi

    # Nothing to check for Hbase, setup always completes
    hbasesetupcomplete=1
else
    hbasesetupcomplete=1
fi

#
# Setup Spark
#

if [ "${SPARK_SETUP}" == "yes" ]
then
    cd ${SPARK_HOME}

    if [ ${SPARK_MODE} != "setuponly" ]
    then
	echo "Starting spark"
	${sparksetupscriptprefix}/start-all.sh
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${SPARK_SLAVE_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Spark daemons to setup"
	sleep ${sleepwait}
	totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Spark Information"
    echo "*"
    echo "* You can view your Spark status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Spark Master: http://${SPARK_MASTER_NODE}:${SPARK_MASTER_WEBUI_PORT}"
    echo "* Spark Worker: http://<WORKERNODE>:${SPARK_WORKER_WEBUI_PORT}"
    echo "* Spark Application Dashboard: http://${SPARK_MASTER_NODE}:${SPARK_APPLICATION_DASHBOARD_PORT}"
    echo "*" 
    echo "* The Spark Master for running jobs is"
    echo "*"
    echo "* spark://${SPARK_MASTER_NODE}:${SPARK_MASTER_PORT}"
    echo "*"
    echo "* To access Spark directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${SPARK_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv SPARK_CONF_DIR \"${SPARK_CONF_DIR}\""
    else
	echo "*   export SPARK_CONF_DIR=\"${SPARK_CONF_DIR}\""
    fi
    echo "*   cd $SPARK_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to run a job:"
    echo "*" 
    echo "*   ${sparkcmdprefix}/spark-class <class> spark://${SPARK_MASTER_NODE}:${SPARK_MASTER_PORT}"

    if [ "${SPARK_MODE}" == "setuponly" ]
    then
	echo "*" 
	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${SPARK_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv SPARK_CONF_DIR \"${SPARK_CONF_DIR}\""
	else
	echo "*   export SPARK_CONF_DIR=\"${SPARK_CONF_DIR}\""
	fi
	echo "*   cd $SPARK_HOME"
	echo "*   ${sparksetupscriptprefix}/start-all.sh" 
    fi

    echo "*" 
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${SPARK_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv SPARK_CONF_DIR \"${SPARK_CONF_DIR}\""
    else
	echo "*   export SPARK_CONF_DIR=\"${SPARK_CONF_DIR}\""
    fi
    echo "*   cd $SPARK_HOME"
    echo "*   ${sparksetupscriptprefix}/stop-all.sh"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv SPARK_HOME \"${SPARK_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export SPARK_HOME=\"${SPARK_HOME}\""
    fi

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	echo "*"
	echo "* If running interactively, sourcing"
	echo "*"
	echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
	echo "*"
	echo "* will set most common environment variables for your job."
    fi
    echo "*" 
    echo "*******************************************************"

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv SPARK_HOME \"${SPARK_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv SPARK_CONF_DIR \"${SPARK_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv SPARK_LOG_DIR \"${SPARK_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv SPARK_MASTER_NODE \"${SPARK_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv SPARK_MASTER_PORT \"${SPARK_MASTER_PORT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv SPARK_SLAVE_COUNT \"${SPARK_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv SPARK_SLAVE_CORE_COUNT \"${SPARK_SLAVE_CORE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export SPARK_HOME=\"${SPARK_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export SPARK_CONF_DIR=\"${SPARK_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export SPARK_LOG_DIR=\"${SPARK_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export SPARK_MASTER_NODE=\"${SPARK_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export SPARK_MASTER_PORT=\"${SPARK_MASTER_PORT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export SPARK_SLAVE_COUNT=\"${SPARK_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export SPARK_SLAVE_CORE_COUNT=\"${SPARK_SLAVE_CORE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi

    # Nothing to check for Spark, setup always completes
    sparksetupcomplete=1
else
    sparksetupcomplete=1
fi

#
# Setup Storm
#

if [ "${STORM_SETUP}" == "yes" ]
then
    if [ ${STORM_MODE} != "setuponly" ]
    then
	echo "Starting storm"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-storm.sh start
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${STORM_WORKERS_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Storm daemons to setup"
	sleep ${sleepwait}
	totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Storm Information"
    echo "*"
    echo "* You can view your Storm status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Storm UI: http://${STORM_MASTER_NODE}:${STORM_UI_PORT}"
    echo "*" 
    echo "* To access Storm directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${STORM_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\""
    else
	echo "*   export STORM_CONF_DIR=\"${STORM_CONF_DIR}\""
    fi
    echo "*   cd $STORM_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to run a job:"
    echo "*" 
    echo "*   ${stormcmdprefix}/storm jar ..."
    echo "*" 

    if [ "${STORM_MODE}" == "setuponly" ]
    then
 	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${STORM_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\""
	else
	    echo "*   export STORM_CONF_DIR=\"${STORM_CONF_DIR}\""
	fi
	echo "*   cd $MAGPIE_SCRIPTS_HOME"
	echo "*   bin/magpie-storm.sh start"
	echo "*" 
    fi

    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${STORM_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\""
    else
	echo "*   export STORM_CONF_DIR=\"${STORM_CONF_DIR}\""
    fi
    echo "*   cd $MAGPIE_SCRIPTS_HOME"
    echo "*   bin/magpie-storm.sh stop"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv STORM_HOME \"${STORM_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export STORM_HOME=\"${STORM_HOME}\""
    fi

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	echo "*"
	echo "* If running interactively, sourcing"
	echo "*"
	echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
	echo "*"
	echo "* will set most common environment variables for your job."
    fi
    echo "*" 
    echo "*******************************************************"

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv STORM_HOME \"${STORM_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv STORM_LOG_DIR \"${STORM_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv STORM_MASTER_NODE \"${STORM_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv STORM_NIMBUS_HOST \"${STORM_NIMBUS_HOST}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv STORM_WORKERS_COUNT \"${STORM_WORKERS_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export STORM_HOME=\"${STORM_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export STORM_CONF_DIR=\"${STORM_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export STORM_LOG_DIR=\"${STORM_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export STORM_MASTER_NODE=\"${STORM_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export STORM_NIMBUS_HOST=\"${STORM_NIMBUS_HOST}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export STORM_WORKERS_COUNT=\"${STORM_WORKERS_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi

    # Nothing to check for Storm, setup always completes
    stormsetupcomplete=1
else
    stormsetupcomplete=1
fi

#
# Setup Tachyon
#

if [ "${TACHYON_SETUP}" == "yes" ]
then
    cd ${TACHYON_HOME}

    if [ ${TACHYON_MODE} != "setuponly" ]
    then
	# Must be done here instead of in magpie-setup-tachyon, b/c
	# if Hadoop is setup, the format needs to contact HDFS
	if [ "${TACHYON_JOURNAL_FOLDER}X" == "X" ]
	then
	    tachyonformat=1
	else
	    if [ ! -d "${TACHYON_JOURNAL_FOLDER}" ]
	    then
		tachyonformat=1

		mkdir -p ${TACHYON_JOURNAL_FOLDER}
		if [ $? -ne 0 ] ; then
		    echo "mkdir failed making ${TACHYON_JOURNAL_FOLDER}"
		    exit 1
		fi
	    else
		tachyonformat=0
	    fi
	fi

	if [ "${tachyonformat}" == "1" ]
	then
	    echo "*******************************************************"
	    echo "* Formatting Tachyon"
	    echo "*******************************************************"
	    ${tachyoncmdprefix}/tachyon format

            # My rough estimate for setup time is 15 seconds per 128 nodes
	    sleepwait=`expr ${TACHYON_SLAVE_COUNT} \/ 128 \* 15`
	    if [ ${sleepwait} -lt 15 ]
	    then
		sleepwait=15
	    fi
	    echo "Waiting ${sleepwait} seconds to allow Tachyon format to complete"
	    sleep ${sleepwait}
	    totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
	fi

	echo "Starting tachyon"
	${tachyoncmdprefix}/tachyon-start.sh -N all NoMount
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${TACHYON_SLAVE_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Tachyon daemons to setup"
	sleep ${sleepwait}
	totalsleepwait=`expr ${totalsleepwait} + ${sleepwait}`
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Tachyon Information"
    echo "*"
    echo "* You can view your Tachyon status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Tachyon UI: http://${TACHYON_MASTER_NODE}:${TACHYON_MASTER_WEB_PORT}"
    echo "*" 
    echo "* To access Tachyon directly, you'll most likely want to:"
    echo "*   ${magpieremotecmd} <WORKERNODE>"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv TACHYON_CONF_DIR \"${TACHYON_CONF_DIR}\""
    else
	echo "*   export TACHYON_CONF_DIR=\"${TACHYON_CONF_DIR}\""
    fi
    echo "*   cd $TACHYON_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example:"
    echo "*" 
    echo "*   ${tachyoncmdprefix}/tachyon tfs ls /"
    echo "*" 

    if [ "${TACHYON_MODE}" == "setuponly" ]
    then
 	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${TACHYON_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv TACHYON_CONF_DIR \"${TACHYON_CONF_DIR}\""
	else
	    echo "*   export TACHYON_CONF_DIR=\"${TACHYON_CONF_DIR}\""
	fi
	echo "*   cd $TACHYON_HOME"
	echo "*   ${tachyoncmdprefix}/tachyon format"
	echo "*   ${tachyoncmdprefix}/tachyon-start.sh -N all NoMount"
	echo "*" 
    fi

    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${TACHYON_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv TACHYON_CONF_DIR \"${TACHYON_CONF_DIR}\""
    else
	echo "*   export TACHYON_CONF_DIR=\"${TACHYON_CONF_DIR}\""
    fi
    echo "*   cd $TACHYON_HOME"
    echo "*   ${tachyoncmdprefix}/tachyon-stop.sh all"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv TACHYON_HOME \"${TACHYON_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export TACHYON_HOME=\"${TACHYON_HOME}\""
    fi

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	echo "*"
	echo "* If running interactively, sourcing"
	echo "*"
	echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
	echo "*"
	echo "* will set most common environment variables for your job."
    fi
    echo "*" 
    echo "*******************************************************"

    if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "setenv TACHYON_HOME \"${TACHYON_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv TACHYON_CONF_DIR \"${TACHYON_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv TACHYON_LOG_DIR \"${TACHYON_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv TACHYON_MASTER_NODE \"${TACHYON_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "setenv TACHYON_SLAVE_COUNT \"${TACHYON_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	else
	    echo "export TACHYON_HOME=\"${TACHYON_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export TACHYON_CONF_DIR=\"${TACHYON_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export TACHYON_LOG_DIR=\"${TACHYON_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export TACHYON_MASTER_NODE=\"${TACHYON_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	    echo "export TACHYON_SLAVE_COUNT=\"${TACHYON_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
	fi
	echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
    fi

    # Nothing to check for Tachyon, setup always completes
    tachyonsetupcomplete=1
else
    tachyonsetupcomplete=1
fi

# Make sure all setup passed
if [ "${zookeepersetupcomplete}" == "1" ] \
    && [ "${hadoopsetupcomplete}" == "1" ] \
    && [ "${hbasesetupcomplete}" == "1" ] \
    && [ "${sparksetupcomplete}" == "1" ] \
    && [ "${stormsetupcomplete}" == "1" ] \
    && [ "${tachyonsetupcomplete}" == "1" ]
then
    setupcomplete=1
else
    setupcomplete=0
fi

if [ "${MAGPIE_JOB_TYPE}" == "script" ]
then
    echo "*******************************************************"
    echo "* Executing script $MAGPIE_SCRIPT_PATH"
    echo "*******************************************************"
    ${MAGPIE_SCRIPT_PATH} &
    scriptpid=$!
    Magpie_wait_script ${scriptpid}
elif [ "${MAGPIE_JOB_TYPE}" == "interactive" ]
then
    echo "*******************************************************"
    echo "* Entering Magpie ${MAGPIE_JOB_TYPE} mode"
    echo "*******************************************************"
    magpiesleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
    magpiesleepamount=`expr ${magpiesleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
    magpiesleepseconds=`expr ${magpiesleepamount}  \* 60`
    sleep ${magpiesleepseconds}
elif [ "${MAGPIE_JOB_TYPE}" == "pig" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	if [ "${PIG_MODE}" == "testpig" ]
	then
	    echo "*******************************************************"
	    echo "* Running Testpig"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-pig-testpig &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${PIG_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing Pig script $PIG_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${PIG_HOME}/${pigcmdprefix}/pig ${PIG_SCRIPT_OPTS} ${PIG_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${PIG_MODE}" == "interactive" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Pig ${PIG_MODE} mode"
	    echo "*******************************************************"
	    pigsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    pigsleepamount=`expr ${pigsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    pigsleepseconds=`expr ${pigsleepamount}  \* 60`
	    sleep ${pigsleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "hadoop" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${HADOOP_HOME}

	if [ "${HADOOP_MODE}" == "terasort" ]
	then
	    echo "*******************************************************"
	    echo "* Running Terasort"
	    echo "*******************************************************"

	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-hadoop-terasort &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HADOOP_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $HADOOP_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${HADOOP_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HADOOP_MODE}" == "interactive" ] \
	    || [ "${HADOOP_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Hadoop ${HADOOP_MODE} mode"
	    echo "*******************************************************"
	    hadoopsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    hadoopsleepamount=`expr ${hadoopsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    hadoopsleepseconds=`expr ${hadoopsleepamount}  \* 60`
	    sleep ${hadoopsleepseconds}
	elif [ "${HADOOP_MODE}" == "upgradehdfs" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Hadoop ${HADOOP_MODE} mode"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-hadoop-upgradehdfs &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "hbase" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${HBASE_HOME}
    
	if [ "${HBASE_MODE}" == "performanceeval" ]
	then
	    echo "*******************************************************"
	    echo "* Running Performance Evaluation"
	    echo "*******************************************************"
	    
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-hbase-performanceeval &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HBASE_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $HBASE_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${HBASE_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HBASE_MODE}" == "interactive" ] \
	    || [ "${HBASE_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Hbase ${HBASE_MODE} mode"
	    echo "*******************************************************"
	    
	    hbasesleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    hbasesleepamount=`expr ${hbasesleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    hbasesleepseconds=`expr ${hbasesleepamount}  \* 60`
	    sleep ${hbasesleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "spark" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${SPARK_HOME}
    
	if [ "${SPARK_MODE}" == "sparkpi" ]
	then
	    echo "*******************************************************"
	    echo "* Running SparkPi"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-spark-sparkpi &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${SPARK_MODE}" == "sparkwordcount" ]
	then
	    echo "*******************************************************"
	    echo "* Running SparkWordCount"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-spark-sparkwordcount &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${SPARK_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $SPARK_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${SPARK_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${SPARK_MODE}" == "interactive" ] \
	    || [ "${SPARK_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Spark ${SPARK_MODE} mode"
	    echo "*******************************************************"
	    
	    sparksleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    sparksleepamount=`expr ${sparksleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    sparksleepseconds=`expr ${sparksleepamount}  \* 60`
	    sleep ${sparksleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "storm" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${STORM_HOME}
    
	if [ "${STORM_MODE}" == "stormwordcount" ]
	then
	    echo "*******************************************************"
	    echo "* Running Storm WordCount"
	    echo "*******************************************************"
	    
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-storm-stormwordcount &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${STORM_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $STORM_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${STORM_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${STORM_MODE}" == "interactive" ] \
	    || [ "${STORM_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Storm ${STORM_MODE} mode"
	    echo "*******************************************************"
	    
	    stormsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    stormsleepamount=`expr ${stormsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    stormsleepseconds=`expr ${stormsleepamount}  \* 60`
	    sleep ${stormsleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "tachyon" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	if [ "${TACHYON_MODE}" == "testtachyon" ]
	then
	    echo "*******************************************************"
	    echo "* Running Testtachyon"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-tachyon-testtachyon &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${TACHYON_MODE}" == "launch" ] \
	    || [ "${TACHYON_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Tachyon ${TACHYON_MODE} mode"
	    echo "*******************************************************"
	    
	    tachyonsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    tachyonsleepamount=`expr ${tachyonsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    tachyonsleepseconds=`expr ${tachyonsleepamount}  \* 60`
	    sleep ${tachyonsleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "zookeeper" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	if [ "${ZOOKEEPER_MODE}" == "zookeeperruok" ]
	then
	    echo "*******************************************************"
	    echo "* Running Zookeeper ruok"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-zookeeper-zookeeperruok &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${ZOOKEEPER_MODE}" == "launch" ] \
	    || [ "${ZOOKEEPER_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Zookeeper ${ZOOKEEPER_MODE} mode"
	    echo "*******************************************************"
	    
	    zookeepersleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    zookeepersleepamount=`expr ${zookeepersleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    zookeepersleepseconds=`expr ${zookeepersleepamount}  \* 60`
	    sleep ${zookeepersleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "testall" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	echo "*******************************************************"
	echo "* Running Magpie TestAll"
	echo "*******************************************************"
	${MAGPIE_SCRIPTS_HOME}/magpie-run-magpie-testall &
	scriptpid=$!
	Magpie_wait_script ${scriptpid}
    fi
fi

if [ "${STORM_SETUP}" == "yes" ]
then
    if [ ${STORM_MODE} != "setuponly" ]
    then
	echo "Stopping storm"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-storm.sh stop
    fi
fi

if [ "${SPARK_SETUP}" == "yes" ]
then
    if [ ${SPARK_MODE} != "setuponly" ]
    then
	cd ${SPARK_HOME}
	
	echo "Stopping spark"
	
	${sparksetupscriptprefix}/stop-all.sh
    fi
fi

if [ "${HBASE_SETUP}" == "yes" ]
then
    if [ ${HBASE_MODE} != "setuponly" ]
    then
	cd ${HBASE_HOME}
	
	echo "Stopping hbase"
	
	if [ "${HBASE_MAJOR_COMPACTION_ON_SHUTDOWN}X" == "X" ] || [ "${HBASE_MAJOR_COMPACTION_ON_SHUTDOWN}" == "yes" ]
	then
	    echo "Doing major compaction before shutting down ..."

	    command="echo list"
	    echo "Running $command in hbase shell" >&2
	    listoutput=`$command | ${hbasecmdprefix}/hbase shell | sed -n '/TABLE/,/seconds/p' | tail -n+2 | head -n -1`

	    for table in ${listoutput}
	    do
		command="echo major_compact '${table}'"
		echo "Running $command in hbase shell" >&2
		$command | ${hbasecmdprefix}/hbase shell
	    done
	fi
	
	${hbasesetupscriptprefix}/stop-hbase.sh
    fi
fi

# Tachyon before Hadoop shutdown, may need to flush
if [ "${TACHYON_SETUP}" == "yes" ]
then
    if [ ${TACHYON_MODE} != "setuponly" ]
    then
	cd ${TACHYON_HOME}

	echo "Stopping tachyon"
	${tachyoncmdprefix}/tachyon-stop.sh all
    fi
fi

if [ "${HADOOP_SETUP}" == "yes" ]
then
    if [ ${HADOOP_MODE} != "setuponly" ]
    then
	cd ${HADOOP_HOME}
	
	echo "Stopping hadoop"

	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${hadoopsetupscriptprefix}/stop-mapred.sh
	    ${hadoopsetupscriptprefix}/stop-jobhistoryserver.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${hadoopsetupscriptprefix}/stop-yarn.sh
	    ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh stop historyserver
	fi

	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
	then
	    echo "Saving namespace before shutting down hdfs ..."

	    if [ "${HDFS_FEDERATION_NAMENODE_COUNT}" -gt 1 ]
	    then
		for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
		do
	            # First namenode is based on master
		    if [ "${i}" == "1" ]
		    then
			federationnamenodehost="${HADOOP_MASTER_NODE}"
		    else
			numline=`expr ${i} - 1`
			federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
		    fi

		    command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${HADOOP_HDFS_NAMENODE_ADDRESS} -safemode enter"
		    echo "Running $command" >&2
		    $command
		    
		    command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${HADOOP_HDFS_NAMENODE_ADDRESS} -saveNamespace"
		    echo "Running $command" >&2
		    $command

		    command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${HADOOP_HDFS_NAMENODE_ADDRESS} -safemode leave"
		    echo "Running $command" >&2
		    $command
		done
	    else
		command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode enter"
		echo "Running $command" >&2
		$command
		
		command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -saveNamespace"
		echo "Running $command" >&2
		$command

		command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode leave"
		echo "Running $command" >&2
		$command
	    fi

	    ${hadoopsetupscriptprefix}/stop-dfs.sh 
	fi
    fi
fi

# Zookeeper teardown comes last, as other things like Hbase & Storm require it

if [ "${ZOOKEEPER_SETUP}" == "yes" ]
then
    if [ "${ZOOKEEPER_MODE}" != "setuponly" ]
    then
	echo "Stopping Zookeeper"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-zookeeper.sh stop
    fi
fi

exit 0

