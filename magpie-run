#!/bin/bash
#############################################################################
#  Copyright (C) 2013 Lawrence Livermore National Security, LLC.
#  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
#  Written by Albert Chu <chu11@llnl.gov>
#  LLNL-CODE-644248
#  
#  This file is part of Magpie, scripts for running Hadoop on
#  traditional HPC systems.  For details, see <URL>.
#  
#  Magpie is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Magpie is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Magpie.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# This script is the core processing script for setting up daemons and
# running jobs.  For the most part, it shouldn't be editted.  See
# job submission files for configuration details.

source ${MAGPIE_SCRIPTS_HOME}/magpie-submission-convert
source ${MAGPIE_SCRIPTS_HOME}/magpie-common-exports
source ${MAGPIE_SCRIPTS_HOME}/magpie-common-functions

if ! Magpie_am_I_master
then
    exit 0
fi

# Output some general info
echo "*******************************************************"
echo "* Magpie General Job Info"
echo "*"
echo "* Job Nodelist: ${MAGPIE_NODELIST}"
echo "* Job Nodecount: ${MAGPIE_NODE_COUNT}"
echo "* Job Timelimit in Minutes: ${MAGPIE_TIMELIMIT_MINUTES}"
echo "* Job Name: ${MAGPIE_JOB_NAME}"
echo "* Job ID: ${MAGPIE_JOB_ID}"
echo "*"
echo "*******************************************************"

#
# Setup ZooKeeper
#

# Zookeeper setup comes first, as other things like Hbase & Storm require it

if [ "${ZOOKEEPER_SETUP}" == "yes" ]
then
    if [ "${ZOOKEEPER_MODE}" != "setuponly" ]
    then
	echo "Starting Zookeeper"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-zookeeper.sh start

        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${ZOOKEEPER_REPLICATION_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Zookeeper daemons to setup"
	sleep ${sleepwait}
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Zookeeper Information"
    echo "*"
    if [ "${ZOOKEEPER_MODE}" == "setuponly" ]
    then
 	echo "* To setup, you probably want to run:" 
	echo "*   ${magpieremotecmd} ${ZOOKEEPER_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv ZOOCFGDIR \"${ZOOKEEPER_CONF_DIR}\""
	else
	    echo "*   export ZOOCFGDIR=\"${ZOOKEEPER_CONF_DIR}\""
	fi
	echo "*   cd $MAGPIE_SCRIPTS_HOME"
	echo "*   bin/magpie-zookeeper.sh start"
	echo "*" 
    fi
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${ZOOKEEPER_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv ZOOCFGDIR \"${ZOOKEEPER_CONF_DIR}\""
    else
	echo "*   export ZOOCFGDIR=\"${ZOOKEEPER_CONF_DIR}\""
    fi
    echo "*   cd $MAGPIE_SCRIPTS_HOME"
    echo "*   bin/magpie-zookeeper.sh stop"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv ZOOKEEPER_HOME \"${ZOOKEEPER_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export ZOOKEEPER_HOME=\"${ZOOKEEPER_HOME}\""
    fi
    echo "*" 
    echo "*******************************************************"
    # Nothing to check for Zookeeper, setup always completes
    zookeepersetupcomplete=1
else
    zookeepersetupcomplete=1
fi

#
# Setup Hadoop
#

if [ "${HADOOP_SETUP}" == "yes" ]
then
    cd ${HADOOP_HOME}

    if [ ${HADOOP_MODE} != "setuponly" ]
    then
	echo "Starting hadoop"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
	then
	    ${hadoopsetupscriptprefix}/start-dfs.sh 
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${hadoopsetupscriptprefix}/start-mapred.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${hadoopsetupscriptprefix}/start-yarn.sh
	fi
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${HADOOP_SLAVE_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allows Hadoop daemons to setup"
	sleep ${sleepwait}
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Hadoop Information"
    echo "*"
    echo "* You can view your Hadoop status by launching a web browser and pointing to ..."
    echo "*"
    if [ ${HADOOP_SETUP_TYPE}  == "MR1" ]
    then
	echo "* Jobtracker: http://${HADOOP_MASTER_NODE}:${MAPRED_JOB_TRACKER_HTTPADDRESS}"
	echo "*"
    elif [ ${HADOOP_SETUP_TYPE}  == "MR2" ]
    then
	echo "* Yarn Resource Manager: http://${HADOOP_MASTER_NODE}:${YARN_RESOURCEMANAGER_WEBAPP_ADDRESS}"
	echo "*"
	echo "* Job History Server: http://${HADOOP_MASTER_NODE}:${HADOOP_JOBHISTORYSERVER_WEBAPP_ADDRESS}"
	echo "*"
    fi
    if [ ${HADOOP_FILESYSTEM_MODE} == "hdfs" ] \
	|| [ ${HADOOP_FILESYSTEM_MODE} == "hdfsoverlustre" ] \
	|| [ ${HADOOP_FILESYSTEM_MODE} == "hdfsovernetworkfs" ]
    then
	echo "* HDFS Namenode: http://${HADOOP_MASTER_NODE}:${HADOOP_HDFS_NAMENODE_HTTPADDRESS}"
	echo "* HDFS DataNode: http://<DATANODE>:${HADOOP_HDFS_DATANODE_HTTPADDRESS}"
	echo "*"
	echo "* HDFS can be accessed at the address:"
	echo "*"
	echo "*   hdfs://${HADOOP_MASTER_NODE}:${HADOOP_HDFS_NAMENODE_ADDRESS}" 
	echo "*" 
    fi
    echo "*" 
    echo "* To access Hadoop directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${HADOOP_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
    else
	echo "*   export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
    fi
    echo "*   cd $HADOOP_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to interact with the Hadoop filesystem:"
    echo "*" 
    echo "*   ${hadoopcmdprefix}/hadoop fs ..."
    echo "*" 
    echo "* To launch jobs you'll want to:"
    echo "*" 
    echo "*   ${hadoopcmdprefix}/hadoop jar ..."
    echo "*" 
    if [ "${PIG_SETUP}" == "yes" ] && [ "${PIG_MODE}" == "interactive" ]
    then
	echo "*"
	echo "* To run pig scripts:"
	echo "*"
	echo "* cd $PIG_HOME"
	echo "* ${pigcmdprefix}/pig ..."
    fi
    if [ "${HADOOP_MODE}" == "setuponly" ]
    then
	echo "*" 
 	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${HADOOP_MASTER_NODE}"
	echo "*   cd $HADOOP_HOME"
	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-dfs.sh" 
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-mapred.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-yarn.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/start-jobhistoryserver.sh"
	fi
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    echo "*   ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh start historyserver"
	fi
    fi

    echo "*" 
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${HADOOP_MASTER_NODE}"
    echo "*   cd $HADOOP_HOME"
    if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-mapred.sh"
    fi
    if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-yarn.sh"
    fi
    if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-dfs.sh"
    fi
    if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/stop-jobhistoryserver.sh"
    fi
    if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
    then
	echo "*   ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh stop historyserver"
    fi
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv HADOOP_HOME \"${HADOOP_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export HADOOP_HOME=\"${HADOOP_HOME}\""
    fi
    if [ "${PIG_SETUP}" == "yes" ]
    then
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv PIG_HOME \"${PIG_HOME}\""
	    echo "*   setenv PIG_CONF_DIR \"${PIG_CONF_DIR}\""
	else
	    echo "*   export PIG_HOME=\"${PIG_HOME}\""
	    echo "*   export PIG_CONF_DIR=\"${PIG_CONF_DIR}\""
	fi
    fi
    echo "*" 
    echo "*******************************************************"

    # Ensure namenode isn't in safe mode.
    #
    # We do not use "-safemode wait", b/c we want to inform the user
    # as we're waiting.
    if [ ${HADOOP_MODE} != "setuponly" ] \
	&& ([ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	|| [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ])
    then
	namenodemaxwaitseconds=`expr ${MAGPIE_STARTUP_TIME} \* 60 - ${sleepwait}`
	namenodemaxwaittimes=`expr ${namenodemaxwaitseconds} \/ 30`
	
	cd ${HADOOP_HOME}
	
	for ((i = 1; i <= ${namenodemaxwaittimes}; i++)); do
	    
	    ${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode get 2>&1 | grep -q -i "off"
	    if [ $? -eq 0 ]
	    then
		break
	    fi
	    echo "Waiting 30 more seconds for namenode to exit safe mode"
	    sleep 30
	done
	
	${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode get 2>&1 | grep -q -i "off"
	if [ $? -ne 0 ] 
	then
	    echo "Namenode never exited safe mode, setup problem or maybe need to increase MAGPIE_STARTUP_TIME"
	    hadoopsetupcomplete=0
	else
	    hadoopsetupcomplete=1
	fi
    else
	hadoopsetupcomplete=1
    fi

    # Setup job history server after namenode comes up, it may need to
    # write/create in HDFS
    if [ ${HADOOP_MODE} != "setuponly" ] && [ "${hadoopsetupcomplete}" == "1" ]
    then
	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${hadoopsetupscriptprefix}/start-jobhistoryserver.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh start historyserver
	fi
    fi
else
    hadoopsetupcomplete=1
fi

#
# Setup Hbase
#

if [ "${HBASE_SETUP}" == "yes" ]
then
    cd ${HBASE_HOME}

    if [ ${HBASE_MODE} != "setuponly" ] && [ "${hadoopsetupcomplete}" == "1" ]
    then
	echo "Starting hbase"
	${hbasesetupscriptprefix}/start-hbase.sh
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${HBASE_REGIONSERVER_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Hbase daemons to setup"
	sleep ${sleepwait}
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Hbase Information"
    echo "*"
    echo "* You can view your Hbase status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Hbase Master: http://${HBASE_MASTER_NODE}:${HBASE_MASTER_INFO_PORT}"
    echo "* Hbase RegionServer: http://<REGIONSERVER>:${HBASE_REGIONSERVER_INFO_PORT}"
    echo "*" 
    echo "* To access Hbase directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${HBASE_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv HBASE_CONF_DIR \"${HBASE_CONF_DIR}\""
    else
	echo "*   export HBASE_CONF_DIR=\"${HBASE_CONF_DIR}\""
    fi
    echo "*   cd $HBASE_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to interact in the Hbase shell :"
    echo "*" 
    echo "*   ${hbasecmdprefix}/hbase shell"

    if [ "${HBASE_MODE}" == "setuponly" ]
    then
	echo "*" 
	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${HBASE_MASTER_NODE}"
	echo "*   cd $HBASE_HOME"
	echo "*   ${hbasesetupscriptprefix}/start-hbase.sh" 
    fi

    echo "*" 
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${HBASE_MASTER_NODE}"
    echo "*   cd $HBASE_HOME"
    echo "*   ${hbasesetupscriptprefix}/stop-hbase.sh"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv HBASE_HOME \"${HBASE_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export HBASE_HOME=\"${HBASE_HOME}\""
    fi
    echo "*" 
    echo "*******************************************************"

    # Nothing to check for Hbase, setup always completes
    hbasesetupcomplete=1
else
    hbasesetupcomplete=1
fi

#
# Setup Spark
#

if [ "${SPARK_SETUP}" == "yes" ]
then
    cd ${SPARK_HOME}

    if [ ${SPARK_MODE} != "setuponly" ]
    then
	echo "Starting spark"
	${sparksetupscriptprefix}/start-all.sh
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${SPARK_SLAVE_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Spark daemons to setup"
	sleep ${sleepwait}
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Spark Information"
    echo "*"
    echo "* You can view your Spark status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Spark Master: http://${SPARK_MASTER_NODE}:${SPARK_MASTER_WEBUI_PORT}"
    echo "* Spark Worker: http://<WORKERNODE>:${SPARK_WORKER_WEBUI_PORT}"
    echo "*" 
    echo "* The Spark Master for running jobs is"
    echo "*"
    echo "* spark://${SPARK_MASTER_NODE}:${SPARK_MASTER_PORT}"
    echo "*"
    echo "* To access Spark directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${SPARK_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv SPARK_CONF_DIR \"${SPARK_CONF_DIR}\""
    else
	echo "*   export SPARK_CONF_DIR=\"${SPARK_CONF_DIR}\""
    fi
    echo "*   cd $SPARK_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to run a job:"
    echo "*" 
    echo "*   ${sparkcmdprefix}/spark-class <class> spark://${SPARK_MASTER_NODE}:${SPARK_MASTER_PORT}"

    if [ "${SPARK_MODE}" == "setuponly" ]
    then
	echo "*" 
	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${SPARK_MASTER_NODE}"
	echo "*   cd $SPARK_HOME"
	echo "*   ${sparksetupscriptprefix}/start-all.sh" 
    fi

    echo "*" 
    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${SPARK_MASTER_NODE}"
    echo "*   cd $SPARK_HOME"
    echo "*   ${sparksetupscriptprefix}/stop-all.sh"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv SPARK_HOME \"${SPARK_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export SPARK_HOME=\"${SPARK_HOME}\""
    fi
    echo "*" 
    echo "*******************************************************"
    # Nothing to check for Spark, setup always completes
    sparksetupcomplete=1
else
    sparksetupcomplete=1
fi

#
# Setup Storm
#

if [ "${STORM_SETUP}" == "yes" ]
then
    if [ ${STORM_MODE} != "setuponly" ]
    then
	echo "Starting storm"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-storm.sh start
	
        # My rough estimate for setup time is 30 seconds per 128 nodes
	sleepwait=`expr ${STORM_WORKERS_COUNT} \/ 128 \* 30`
	if [ ${sleepwait} -lt 30 ]
	then
            sleepwait=30
	fi
	echo "Waiting ${sleepwait} seconds to allow Storm daemons to setup"
	sleep ${sleepwait}
    fi

    echo "*******************************************************"
    echo "*"
    echo "* Storm Information"
    echo "*"
    echo "* You can view your Storm status by launching a web browser and pointing to ..."
    echo "*"
    echo "* Storm UI: http://${STORM_MASTER_NODE}:${STORM_UI_PORT}"
    echo "*" 
    echo "* To access Storm directly, you'll want to:"
    echo "*   ${magpieremotecmd} ${STORM_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\""
    else
	echo "*   export STORM_CONF_DIR=\"${STORM_CONF_DIR}\""
    fi
    echo "*   cd $STORM_HOME"
    echo "*"
    echo "* Then you can do as you please.  For example to run a job:"
    echo "*" 
    echo "*   ${stormcmdprefix}/storm jar ..."
    echo "*" 

    if [ "${STORM_MODE}" == "setuponly" ]
    then
 	echo "* To setup, you probably want to run:" 
	echo "*"
	echo "*   ${magpieremotecmd} ${STORM_MASTER_NODE}"
	if echo $SHELL | grep -q csh
	then
	    echo "*   setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\""
	else
	    echo "*   export STORM_CONF_DIR=\"${STORM_CONF_DIR}\""
	fi
	echo "*   cd $MAGPIE_SCRIPTS_HOME"
	echo "*   bin/magpie-storm.sh start"
	echo "*" 
    fi

    echo "* To end/cleanup your session, kill the daemons via:"
    echo "*" 
    echo "*   ${magpieremotecmd} ${STORM_MASTER_NODE}"
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv STORM_CONF_DIR \"${STORM_CONF_DIR}\""
    else
	echo "*   export STORM_CONF_DIR=\"${STORM_CONF_DIR}\""
    fi
    echo "*   cd $MAGPIE_SCRIPTS_HOME"
    echo "*   bin/magpie-storm.sh stop"
    echo "*" 
    echo "* Some additional environment variables you may sometimes wish to set"
    echo "*" 
    if echo $SHELL | grep -q csh
    then
	echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
	echo "*   setenv STORM_HOME \"${STORM_HOME}\""
    else
	echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
	echo "*   export STORM_HOME=\"${STORM_HOME}\""
    fi
    echo "*" 
    echo "*******************************************************"
    # Nothing to check for Storm, setup always completes
    stormsetupcomplete=1
else
    stormsetupcomplete=1
fi

# Make sure all setup passed
if [ "${zookeepersetupcomplete}" == "1" ] \
    && [ "${hadoopsetupcomplete}" == "1" ] \
    && [ "${hbasesetupcomplete}" == "1" ] \
    && [ "${sparksetupcomplete}" == "1" ] \
    && [ "${stormsetupcomplete}" == "1" ]
then
    setupcomplete=1
else
    setupcomplete=0
fi

if [ "${MAGPIE_JOB_TYPE}" == "script" ]
then
    echo "*******************************************************"
    echo "* Executing script $MAGPIE_SCRIPT_PATH"
    echo "*******************************************************"
    ${MAGPIE_SCRIPT_PATH} &
    scriptpid=$!
    Magpie_wait_script ${scriptpid}
elif [ "${MAGPIE_JOB_TYPE}" == "interactive" ]
then
    echo "*******************************************************"
    echo "* Entering Magpie ${MAGPIE_JOB_TYPE} mode"
    echo "*******************************************************"
    magpiesleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
    magpiesleepamount=`expr ${magpiesleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
    magpiesleepseconds=`expr ${magpiesleepamount}  \* 60`
    sleep ${magpiesleepseconds}
elif [ "${MAGPIE_JOB_TYPE}" == "pig" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	if [ "${PIG_MODE}" == "testpig" ]
	then
	    echo "*******************************************************"
	    echo "* Running Testpig"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-testpig &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${PIG_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing Pig script $PIG_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${PIG_HOME}/${pigcmdprefix}/pig ${PIG_SCRIPT_OPTS} ${PIG_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${PIG_MODE}" == "interactive" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Pig ${PIG_MODE} mode"
	    echo "*******************************************************"
	    pigsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    pigsleepamount=`expr ${pigsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    pigsleepseconds=`expr ${pigsleepamount}  \* 60`
	    sleep ${pigsleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "hadoop" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${HADOOP_HOME}

	if [ "${HADOOP_MODE}" == "terasort" ]
	then
	    echo "*******************************************************"
	    echo "* Running Terasort"
	    echo "*******************************************************"

	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-terasort &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HADOOP_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $HADOOP_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${HADOOP_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HADOOP_MODE}" == "interactive" ] \
	    || [ "${HADOOP_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Hadoop ${HADOOP_MODE} mode"
	    echo "*******************************************************"
	    hadoopsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    hadoopsleepamount=`expr ${hadoopsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    hadoopsleepseconds=`expr ${hadoopsleepamount}  \* 60`
	    sleep ${hadoopsleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "hbase" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${HBASE_HOME}
    
	if [ "${HBASE_MODE}" == "performanceeval" ]
	then
	    echo "*******************************************************"
	    echo "* Running Performance Evaluation"
	    echo "*******************************************************"
	    
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-performanceeval &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HBASE_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $HBASE_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${HBASE_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${HBASE_MODE}" == "interactive" ] \
	    || [ "${HBASE_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Hbase ${HBASE_MODE} mode"
	    echo "*******************************************************"
	    
	    hbasesleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    hbasesleepamount=`expr ${hbasesleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    hbasesleepseconds=`expr ${hbasesleepamount}  \* 60`
	    sleep ${hbasesleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "spark" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${SPARK_HOME}
    
	if [ "${SPARK_MODE}" == "sparkpi" ]
	then
	    echo "*******************************************************"
	    echo "* Running SparkPi"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-sparkpi &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${SPARK_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $SPARK_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${SPARK_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${SPARK_MODE}" == "interactive" ] \
	    || [ "${SPARK_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Spark ${SPARK_MODE} mode"
	    echo "*******************************************************"
	    
	    sparksleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    sparksleepamount=`expr ${sparksleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    sparksleepseconds=`expr ${sparksleepamount}  \* 60`
	    sleep ${sparksleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "storm" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	cd ${STORM_HOME}
    
	if [ "${STORM_MODE}" == "stormwordcount" ]
	then
	    echo "*******************************************************"
	    echo "* Running Storm WordCount"
	    echo "*******************************************************"
	    
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-stormwordcount &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${STORM_MODE}" == "script" ]
	then
	    echo "*******************************************************"
	    echo "* Executing script $STORM_SCRIPT_PATH"
	    echo "*******************************************************"
	    ${STORM_SCRIPT_PATH} &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${STORM_MODE}" == "interactive" ] \
	    || [ "${STORM_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Storm ${STORM_MODE} mode"
	    echo "*******************************************************"
	    
	    stormsleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    stormsleepamount=`expr ${stormsleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    stormsleepseconds=`expr ${stormsleepamount}  \* 60`
	    sleep ${stormsleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "zookeeper" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	if [ "${ZOOKEEPER_MODE}" == "zookeeperruok" ]
	then
	    echo "*******************************************************"
	    echo "* Running Zookeeper ruok"
	    echo "*******************************************************"
	    ${MAGPIE_SCRIPTS_HOME}/magpie-run-zookeeperruok &
	    scriptpid=$!
	    Magpie_wait_script ${scriptpid}
	elif [ "${ZOOKEEPER_MODE}" == "launch" ] \
	    || [ "${ZOOKEEPER_MODE}" == "setuponly" ]
	then
	    echo "*******************************************************"
	    echo "* Entering Zookeeper ${ZOOKEEPER_MODE} mode"
	    echo "*******************************************************"
	    
	    zookeepersleepamounttemp=`expr ${MAGPIE_TIMELIMIT_MINUTES} - ${MAGPIE_STARTUP_TIME}`
	    zookeepersleepamount=`expr ${zookeepersleepamounttemp} - ${MAGPIE_SHUTDOWN_TIME}`
	    zookeepersleepseconds=`expr ${zookeepersleepamount}  \* 60`
	    sleep ${zookeepersleepseconds}
	fi
    fi
elif [ "${MAGPIE_JOB_TYPE}" == "testall" ]
then
    if [ "${setupcomplete}" == "1" ]
    then
	echo "*******************************************************"
	echo "* Running Magpie TestAll"
	echo "*******************************************************"
	${MAGPIE_SCRIPTS_HOME}/magpie-run-testall &
	scriptpid=$!
	Magpie_wait_script ${scriptpid}
    fi
fi

if [ "${STORM_SETUP}" == "yes" ]
then
    if [ ${STORM_MODE} != "setuponly" ]
    then
	echo "Stopping storm"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-storm.sh stop
    fi
fi

if [ "${SPARK_SETUP}" == "yes" ]
then
    if [ ${SPARK_MODE} != "setuponly" ]
    then
	cd ${SPARK_HOME}
	
	echo "Stopping spark"
	
	${sparksetupscriptprefix}/stop-all.sh
    fi
fi

if [ "${HBASE_SETUP}" == "yes" ]
then
    if [ ${HBASE_MODE} != "setuponly" ]
    then
	cd ${HBASE_HOME}
	
	echo "Stopping hbase"
	
	if [ "${HBASE_MAJOR_COMPACTION_ON_SHUTDOWN}X" == "X" ] || [ "${HBASE_MAJOR_COMPACTION_ON_SHUTDOWN}" == "yes" ]
	then
	    echo "Doing major compaction before shutting down ..."

	    command="echo list"
	    echo "Running $command in hbase shell" >&2
	    listoutput=`$command | ${hbasecmdprefix}/hbase shell | sed -n '/TABLE/,/seconds/p' | tail -n+2 | head -n -1`

	    for table in ${listoutput}
	    do
		command="echo major_compact '${table}'"
		echo "Running $command in hbase shell" >&2
		$command | ${hbasecmdprefix}/hbase shell
	    done
	fi
	
	${hbasesetupscriptprefix}/stop-hbase.sh
    fi
fi

if [ "${HADOOP_SETUP}" == "yes" ]
then
    if [ ${HADOOP_MODE} != "setuponly" ]
    then
	cd ${HADOOP_HOME}
	
	echo "Stopping hadoop"

	if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
	then
	    ${hadoopsetupscriptprefix}/stop-mapred.sh
	    ${hadoopsetupscriptprefix}/stop-jobhistoryserver.sh
	fi
	
	if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
	then
	    ${hadoopsetupscriptprefix}/stop-yarn.sh
	    ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh stop historyserver
	fi

	if [ "$HADOOP_FILESYSTEM_MODE" == "hdfs" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsoverlustre" ] \
	    || [ "$HADOOP_FILESYSTEM_MODE" == "hdfsovernetworkfs" ]
	then
	    echo "Saving namespace before shutting down hdfs ..."

	    command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode enter"
	    echo "Running $command" >&2
	    $command

	    command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -saveNamespace"
	    echo "Running $command" >&2
	    $command

	    command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode leave"
	    echo "Running $command" >&2
	    $command

	    ${hadoopsetupscriptprefix}/stop-dfs.sh 
	fi
    fi
fi

# Zookeeper teardown comes last, as other things like Hbase & Storm require it

if [ "${ZOOKEEPER_SETUP}" == "yes" ]
then
    if [ "${ZOOKEEPER_MODE}" != "setuponly" ]
    then
	echo "Stopping Zookeeper"
	${MAGPIE_SCRIPTS_HOME}/bin/magpie-zookeeper.sh stop
    fi
fi

exit 0

