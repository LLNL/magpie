#!/bin/bash
#############################################################################
#  Copyright (C) 2013-2015 Lawrence Livermore National Security, LLC.
#  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).
#  Written by Albert Chu <chu11@llnl.gov>
#  LLNL-CODE-644248
#  
#  This file is part of Magpie, scripts for running Hadoop on
#  traditional HPC systems.  For details, see https://github.com/llnl/magpie.
#  
#  Magpie is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Magpie is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Magpie.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# These are functions to be called by magpie-run

source ${MAGPIE_SCRIPTS_HOME}/magpie-constants
source ${MAGPIE_SCRIPTS_HOME}/magpie-exports-submission-type
source ${MAGPIE_SCRIPTS_HOME}/magpie-exports-dirs
source ${MAGPIE_SCRIPTS_HOME}/magpie-exports-user
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-node-identification
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-hdfs
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-job-management
source ${MAGPIE_SCRIPTS_HOME}/magpie-lib-helper

Magpie_run_start_hadoop () {
    if [ "${HADOOP_SETUP}" == "yes" ] && [ "${magpie_run_prior_startup_successful}" == "true" ]
    then
        local hdfs_was_setup=0

        cd ${HADOOP_HOME}

        if [ ${HADOOP_MODE} != "setuponly" ]
        then
            echo "Starting hadoop"
            local hadoop_should_be_setup=1

            if Magpie_hadoop_filesystem_mode_is_hdfs_type
            then
                if Magpie_hadoop_filesystem_mode_is_hdfs_on_network_type
                then
                    # Sets magpie_networkedhdfspath & magpie_hdfs_stored_version_path
                    Magpie_get_hdfs_stored_version_path
                    # Sets magpie_networkedhdfspath & magpie_hdfs_stored_nodecount_path
                    Magpie_get_hdfs_stored_nodecount_path

                    # Older versions of Magpie didn't store this variable
                    if [ -f ${magpie_hdfs_stored_version_path} ]
                    then
                        hdfsstoredversion=`cat ${magpie_hdfs_stored_version_path}`

                        # 0 is =, 1 is >, 2 is <
                        Magpie_vercomp ${HADOOP_VERSION} ${hdfsstoredversion}
                        local vercomp_result=$?
                        if [ "${vercomp_result}" != "0" ]
                        then
                            if [ "${vercomp_result}" == "1" ]
                            then
                                echo "**** HDFS Issue ****"
                                echo "HDFS version at mount ${magpie_networkedhdfspath} is older than ${HADOOP_VERSION}."
                                if [ "${HADOOP_MODE}" != "upgradehdfs" ]
                                then
                                    echo "With newer Hadoop versions, you can upgrade HDFS via HADOOP_MODE=upgradehdfs"
                                    echo "Or if you wish to use a newer Hadoop version without upgrading HDFS, you can setup HDFS on another path"
                                fi
                                echo "**** HDFS Issue ****"
                            else
                                echo "**** HDFS Issue ****"
                                echo "HDFS version at mount ${magpie_networkedhdfspath} is newer than ${HADOOP_VERSION}."
                                echo "Please use a newer Hadoop version."
                                echo "Or if you wish to use an older Hadoop version, you can setup HDFS on another path"
                                echo "**** HDFS Issue ****"
                            fi

                            # or ...vercomp_result == 1 && hadoop_mode == upgradehdfs
                            if [ "${vercomp_result}" != "1" ] || [ "${HADOOP_MODE}" != "upgradehdfs" ]
                            then
                                hadoop_should_be_setup=0
                            fi
                        fi
                    fi

                    # Older nodecounts of Magpie didn't store this variable
                    if [ -f ${magpie_hdfs_stored_nodecount_path} ]
                    then
                        local hdfsstorednodecount=`cat ${magpie_hdfs_stored_nodecount_path}`

                        if [ "${HADOOP_SLAVE_COUNT}" -lt "${hdfsstorednodecount}" ]
                        then
                            local ninteypercentnodes=`echo "${hdfsstorednodecount} * .9" | bc -l | xargs printf "%1.0f"`
                            echo "**** HDFS Issue ****"
                            echo "HDFS was last built using a larger slave node count of ${hdfsstorednodecount}, compared to this job's ${HADOOP_SLAVE_COUNT}"
                            echo "Because of this, it is very likely the HDFS Namenode will not be able to find all HDFS blocks."

                            if [ "${HADOOP_SLAVE_COUNT}" -gt "${ninteypercentnodes}" ]
                            then
                                echo "The current slave count of ${HADOOP_SLAVE_COUNT} is atleast 90% of ${hdfsstorednodecount}, so HDFS will attempt to be"
                                echo "started.  However, it is not recommended for future runs and there is still a chance HDFS will not start."
                            else
                                echo "If you truly desire to use fewer nodes, setup HDFS on another path or consider going through a decommissioning process to"
                                echo "reduce the number of nodes your HDFS is built on via HADOOP_MODE=decommissionhdfsnodes."
                                hadoop_should_be_setup=0
                            fi
                            echo "**** HDFS Issue ****"
                        fi
                    fi
                fi

                if [ "${MAGPIE_JOB_TYPE}" == "hadoop" ] && [ "${HADOOP_MODE}" == "upgradehdfs" ]
                then
                    local startdfsoptions="-upgrade"
                fi

                if [ "${hadoop_should_be_setup}" == "1" ]
                then
                    # Make variables unspecified for launching
                    Magpie_make_all_local_dirs_unspecified

                    ${hadoopsetupscriptprefix}/start-dfs.sh ${startdfsoptions}
                    hdfs_was_setup=1

                    # Make variables specific now within Magpie
                    Magpie_make_all_local_dirs_node_specific
                fi

                if [ "${hdfs_was_setup}" == "1" ] \
                    && Magpie_hadoop_filesystem_mode_is_hdfs_on_network_type
                then
                    if [ "${HADOOP_MODE}" != "upgradehdfs" ]
                    then
                        rm -f ${magpie_hdfs_stored_version_path}
                        echo "${HADOOP_VERSION}" > ${magpie_hdfs_stored_version_path}
                    fi

                    if [ -f ${magpie_hdfs_stored_nodecount_path} ]
                    then
                        local nodecount=`cat ${magpie_hdfs_stored_nodecount_path}`
                        if [ "${nodecount}" -lt "${HADOOP_SLAVE_COUNT}" ]
                        then
                            nodecount=${HADOOP_SLAVE_COUNT}
                        fi
                    else
                        local nodecount=${HADOOP_SLAVE_COUNT}
                    fi
                    rm -f ${magpie_hdfs_stored_nodecount_path}
                    echo "${nodecount}" > ${magpie_hdfs_stored_nodecount_path}
                fi
            fi
            
            if [ "${hadoop_should_be_setup}" == "1" ]
            then
                # Make variables unspecified for shutdown
                Magpie_make_all_local_dirs_unspecified

                if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
                then
                    ${hadoopsetupscriptprefix}/start-mapred.sh
                fi
                
                if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
                then
                    ${hadoopsetupscriptprefix}/start-yarn.sh
                fi

                # Make variables specific now within Magpie
                Magpie_make_all_local_dirs_node_specific
                
                # My rough estimate for setup time is 30 seconds per 128 nodes
                local sleepwait=`expr ${HADOOP_SLAVE_COUNT} \/ 128 \* 30`
                if [ ${sleepwait} -lt 30 ]
                then
                    sleepwait=30
                fi
                echo "Waiting ${sleepwait} seconds to allows Hadoop daemons to setup"
                sleep ${sleepwait}
                magpie_run_total_sleep_wait=`expr ${magpie_run_total_sleep_wait} + ${sleepwait}`
            fi
        fi

        if [ "${hadoop_should_be_setup}" == "1" ] || [ ${HADOOP_MODE} == "setuponly" ]
        then
            echo "*******************************************************"
            echo "*"
            echo "* Hadoop Information"
            echo "*"
            echo "* You can view your Hadoop status by launching a web browser and pointing to ..."
            echo "*"
            if [ ${HADOOP_SETUP_TYPE}  == "MR1" ]
            then
                echo "* Jobtracker: http://${HADOOP_MASTER_NODE}:${default_mapred_job_tracker_httpaddress}"
                echo "*"
            elif [ ${HADOOP_SETUP_TYPE}  == "MR2" ]
            then
                echo "* Yarn Resource Manager: http://${HADOOP_MASTER_NODE}:${default_yarn_resourcemanager_webapp_address}"
                echo "*"
                echo "* Job History Server: http://${HADOOP_MASTER_NODE}:${default_hadoop_jobhistoryserver_webapp_address}"
                echo "*"
            fi
            if Magpie_hadoop_filesystem_mode_is_hdfs_type
            then
                if Magpie_hdfs_federation_enabled
                then
                    for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
                    do
                        # First namenode is based on master
                        if [ "${i}" == "1" ]
                        then
                            local federationnamenodehost="${HADOOP_MASTER_NODE}"
                        else
                            local numline=`expr ${i} - 1`
                            local federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
                        fi
                        echo "* HDFS Namenode ${i}: http://${federationnamenodehost}:${default_hadoop_hdfs_namenode_httpaddress}"
                    done
                else
                    echo "* HDFS Namenode: http://${HADOOP_MASTER_NODE}:${default_hadoop_hdfs_namenode_httpaddress}"
                fi
                echo "* HDFS DataNode: http://<DATANODE>:${default_hadoop_hdfs_datanode_httpaddress}"
                echo "*"
                echo "* HDFS can be accessed directly at:"
                echo "*"
                if Magpie_hdfs_federation_enabled
                then
                    for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
                    do
                        # First namenode is based on master
                        if [ "${i}" == "1" ]
                        then
                            local federationnamenodehost="${HADOOP_MASTER_NODE}"
                        else
                            local numline=`expr ${i} - 1`
                            local federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
                        fi
                        echo "* hdfs://${federationnamenodehost}:${default_hadoop_hdfs_namenode_address}"
                    done
                else
                    echo "*   hdfs://${HADOOP_MASTER_NODE}:${default_hadoop_hdfs_namenode_address}" 
                fi
                echo "*" 
            fi
            echo "*" 
            echo "* To access Hadoop directly, you'll want to:"
            echo "*"
            echo "*   ${MAGPIE_REMOTE_CMD:-ssh}${MAGPIE_REMOTE_CMD_OPTS:+" "}${MAGPIE_REMOTE_CMD_OPTS} ${HADOOP_MASTER_NODE}"
            if echo $MAGPIE_SHELL | grep -q csh
            then
                echo "*   setenv JAVA_HOME \"${JAVA_HOME}\""
                echo "*   setenv HADOOP_HOME \"${HADOOP_HOME}\""
                echo "*   setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\""
                if [ "${MAGPIE_NO_LOCAL_DIR}" == "yes" ]
                then
                    echo "*   setenv HADOOP_CLIENT_OPTS \"-Djava.io.tmpdir=${HADOOP_LOCAL_SCRATCHSPACE_DIR} -XX:-UsePerfData\"" 
                fi
            else
                echo "*   export JAVA_HOME=\"${JAVA_HOME}\""
                echo "*   export HADOOP_HOME=\"${HADOOP_HOME}\""
                echo "*   export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\""
                if [ "${MAGPIE_NO_LOCAL_DIR}" == "yes" ]
                then
                    echo "*   export HADOOP_CLIENT_OPTS=\"-Djava.io.tmpdir=${HADOOP_LOCAL_SCRATCHSPACE_DIR} -XX:-UsePerfData\"" 
                fi
            fi
            echo "*"
            echo "* Then you can do as you please.  For example to interact with the Hadoop filesystem:"
            echo "*" 
            if echo ${HADOOP_VERSION} | grep -q -E "2\.[0-9]\.[0-9]"
            then 
                echo "*   \$HADOOP_HOME/${hadoopcmdprefix}/hdfs dfs ..."
            else
                echo "*   \$HADOOP_HOME/${hadoopcmdprefix}/hadoop fs ..."
            fi
            echo "*" 
            echo "* To launch jobs you'll want to:"
            echo "*" 
            echo "*   \$HADOOP_HOME/${hadoopcmdprefix}/hadoop jar ..."
            echo "*" 
            if [ "${HADOOP_MODE}" == "setuponly" ]
            then
                echo "*" 
                echo "* To setup, login and set environment variables per the"
                echo "* instructions above, then run:"
                echo "*"
                if Magpie_hadoop_filesystem_mode_is_hdfs_type
                then
                    echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/start-dfs.sh" 
                fi
                if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
                then
                    echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/start-mapred.sh"
                fi
                if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
                then
                    echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/start-yarn.sh"
                fi
                if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
                then
                    echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/start-jobhistoryserver.sh"
                fi
                if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
                then
                    echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh start historyserver"
                fi
            fi
            echo "*" 
            echo "* To end/cleanup your session & kill all daemons, login and set"
            echo "* environment variables per the instructions above, then run:"
            echo "*" 
            if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
            then
                echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/stop-mapred.sh"
            fi
            if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
            then
                echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/stop-yarn.sh"
            fi
            if Magpie_hadoop_filesystem_mode_is_hdfs_type
            then
                echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/stop-dfs.sh"
            fi
            if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
            then
                echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/stop-jobhistoryserver.sh"
            fi
            if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
            then
                echo "*   $HADOOP_HOME/${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh stop historyserver"
            fi
            if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
            then
                echo "*"
                echo "* If running interactively, sourcing"
                echo "*"
                echo "* ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}"
                echo "*"
                echo "* will set most common environment variables for your job."
            fi
            echo "*" 
            echo "*******************************************************"

            if [ "${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}X" != "X" ]
            then
                if echo $MAGPIE_SHELL | grep -q csh
                then
                    echo "setenv HADOOP_HOME \"${HADOOP_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "setenv HADOOP_CONF_DIR \"${HADOOP_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "setenv HADOOP_LOG_DIR \"${HADOOP_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "setenv HADOOP_MASTER_NODE \"${HADOOP_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "setenv HADOOP_SLAVE_COUNT \"${HADOOP_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "setenv HADOOP_SLAVE_CORE_COUNT \"${HADOOP_SLAVE_CORE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    if Magpie_hadoop_filesystem_mode_is_hdfs_type
                    then
                        echo "setenv HADOOP_NAMENODE \"${HADOOP_NAMENODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                        echo "setenv HADOOP_NAMENODE_PORT \"${HADOOP_NAMENODE_PORT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    fi
                    echo "setenv HADOOP_VERSION \"${HADOOP_VERSION}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    if [ "${MAGPIE_NO_LOCAL_DIR}" == "yes" ]
                    then
                        echo "setenv HADOOP_CLIENT_OPTS \"-Djava.io.tmpdir=${HADOOP_LOCAL_SCRATCHSPACE_DIR} -XX:-UsePerfData\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT} 
                    fi
                else
                    echo "export HADOOP_HOME=\"${HADOOP_HOME}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "export HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "export HADOOP_LOG_DIR=\"${HADOOP_LOG_DIR}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "export HADOOP_MASTER_NODE=\"${HADOOP_MASTER_NODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "export HADOOP_SLAVE_COUNT=\"${HADOOP_SLAVE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    echo "export HADOOP_SLAVE_CORE_COUNT=\"${HADOOP_SLAVE_CORE_COUNT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    if Magpie_hadoop_filesystem_mode_is_hdfs_type
                    then
                        echo "export HADOOP_NAMENODE=\"${HADOOP_NAMENODE}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                        echo "export HADOOP_NAMENODE_PORT=\"${HADOOP_NAMENODE_PORT}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    fi
                    echo "export HADOOP_VERSION=\"${HADOOP_VERSION}\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    if [ "${MAGPIE_NO_LOCAL_DIR}" == "yes" ]
                    then
                        echo "export HADOOP_CLIENT_OPTS=\"-Djava.io.tmpdir=${HADOOP_LOCAL_SCRATCHSPACE_DIR} -XX:-UsePerfData\"" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
                    fi
                fi
                echo "" >> ${MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT}
            fi
        fi

        # Ensure namenode isn't in safe mode.
        #
        # We do not use "-safemode wait", b/c we want to inform the user
        # as we're waiting.
        if [ ${HADOOP_MODE} != "setuponly" ] \
            && Magpie_hadoop_filesystem_mode_is_hdfs_type
        then
            if [ "${hdfs_was_setup}" == "1" ]
            then
                local magpiestartuptimeseconds=`expr ${magpie_startup_time_value} \* 60`

                if [ "${magpie_run_total_sleep_wait}" -lt "${magpiestartuptimeseconds}" ]
                then  
                    # Could be more dynamic w/ slurm call to determine current
                    # run time, but probably is sufficient for this trivial
                    # part.  Minimally, have to leave the magpie_run_total_sleep_wait code
                    # around for non-slurm systems.
                    local namenodemaxwaitseconds=`expr ${magpiestartuptimeseconds} - ${magpie_run_total_sleep_wait}`
                    
                    if [ "${namenodemaxwaitseconds}" -lt 30 ]
                    then
                        namenodemaxwaitseconds=30
                    fi
                    
                    local namenodemaxwaittimes=`expr ${namenodemaxwaitseconds} \/ 30`
                else
                    local namenodemaxwaittimes=1
                fi
                
                cd ${HADOOP_HOME}

                local exittedsafemode=0
                
                for i in `seq 1 ${namenodemaxwaittimes}`
                do
                    if Magpie_hdfs_federation_enabled
                    then
                        local exittedsafemodeflag=1

                        for j in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
                        do
                            
                            # First namenode is based on master
                            if [ "${j}" == "1" ]
                            then
                                local federationnamenodehost="${HADOOP_MASTER_NODE}"
                            else
                                local numline=`expr ${j} - 1`
                                local federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
                            fi

                            ${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${default_hadoop_hdfs_namenode_address} -safemode get 2>&1 | grep -q -i "off"
                            if [ $? -ne 0 ]
                            then
                                exittedsafemodeflag=0
                            fi
                        done

                        if [ "${exittedsafemodeflag}" == "1" ]
                        then
                            exittedsafemode=1
                            break
                        fi
                    else
                        ${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode get 2>&1 | grep -q -i "off"
                        if [ $? -eq 0 ]
                        then
                            exittedsafemode=1
                            break
                        fi
                    fi

                    echo "Waiting 30 more seconds for namenode to exit safe mode"
                    sleep 30
                    magpie_run_total_sleep_wait=`expr ${magpie_run_total_sleep_wait} + 30`
                done
                
                if [ "${exittedsafemode}" == "0" ]
                then
                    echo "Namenode never exited safe mode, setup problem or maybe need to increase MAGPIE_STARTUP_TIME"
                    magpie_run_hadoop_should_be_torndown=1
                    magpie_run_hadoop_setup_successful=0
                    magpie_run_prior_startup_successful=false
                else
                    magpie_run_hadoop_should_be_torndown=1
                    magpie_run_hadoop_setup_successful=1
                fi
            else
                magpie_run_hadoop_should_be_torndown=0
                magpie_run_hadoop_setup_successful=0
                magpie_run_prior_startup_successful=false
            fi
        else
            magpie_run_hadoop_should_be_torndown=1
            magpie_run_hadoop_setup_successful=1
        fi

        # Setup job history server after namenode comes up, it may need to
        # write/create in HDFS
        if [ ${HADOOP_MODE} != "setuponly" ] && [ "${magpie_run_hadoop_setup_successful}" == "1" ]
        then
            if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
            then
                ${hadoopsetupscriptprefix}/start-jobhistoryserver.sh
            fi
            
            if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
            then
                ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh start historyserver
            fi
        fi

        # A number of applications assume the user home directory has been
        # created.  If it hasn't yet, lets create it for the user.
        if [ "${magpie_run_hadoop_setup_successful}" == "1" ] && [ ${HADOOP_MODE} != "setuponly" ]
        then
            if Magpie_hadoop_filesystem_mode_is_hdfs_type
            then
                ${hadoopcmdprefix}/hadoop fs -ls "/user/${USER}" >& /dev/null
                if [ $? -ne 0 ]
                then
                    echo "User home directory /user/${USER} not found, creating it"
                    ${hadoopcmdprefix}/hadoop fs -mkdir -p "/user/${USER}"
                fi
            fi
        fi
    else
        magpie_run_hadoop_should_be_torndown=0
        magpie_run_hadoop_setup_successful=1
    fi
}

Magpie_run_hadoop () {
    if [ "${HADOOP_MODE}" == "terasort" ]
    then
        echo "*******************************************************"
        echo "* Running Terasort"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute script ${MAGPIE_SCRIPTS_HOME}/magpie-run-job-hadoop-terasort &
        local scriptpid=$!
        Magpie_wait_script_sigusr2_on_job_timeout ${scriptpid}
    elif [ "${HADOOP_MODE}" == "script" ]
    then
        echo "*******************************************************"
        echo "* Executing script $HADOOP_SCRIPT_PATH $HADOOP_SCRIPT_ARGS"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute script ${HADOOP_SCRIPT_PATH} ${HADOOP_SCRIPT_ARGS} &
        local scriptpid=$!
        Magpie_wait_script_sigusr2_on_job_timeout ${scriptpid}
    elif [ "${HADOOP_MODE}" == "interactive" ] || [ "${HADOOP_MODE}" == "launch" ] || [ "${HADOOP_MODE}" == "hdfsonly" ]
    then
        echo "*******************************************************"
        echo "* Entering Hadoop ${HADOOP_MODE} mode"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute interactive &
        local scriptpid=$!
        wait $scriptpid
    elif [ "${HADOOP_MODE}" == "setuponly" ]
    then
        echo "*******************************************************"
        echo "* Entering Hadoop ${HADOOP_MODE} mode"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-job-sleep countdown &
        local scriptpid=$!
        wait ${scriptpid}
    elif [ "${HADOOP_MODE}" == "upgradehdfs" ]
    then
        echo "*******************************************************"
        echo "* Entering Hadoop ${HADOOP_MODE} mode"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute scriptnokill ${MAGPIE_SCRIPTS_HOME}/magpie-run-job-hadoop-upgradehdfs &
        local scriptpid=$!
        Magpie_wait_script_sigusr2_on_job_timeout ${scriptpid}

        if [ $? -eq 0 ]
        then
            # Sets magpie_hdfs_stored_version_path
            Magpie_get_hdfs_stored_version_path

            if [ "${magpie_hdfs_stored_version_path}X" != "X" ]
            then
                rm -f ${magpie_hdfs_stored_version_path}
                echo "${HADOOP_VERSION}" > ${magpie_hdfs_stored_version_path}
            fi
        fi
    elif [ "${HADOOP_MODE}" == "decommissionhdfsnodes" ]
    then
        echo "*******************************************************"
        echo "* Entering Hadoop ${HADOOP_MODE} mode"
        echo "*******************************************************"
        ${MAGPIE_SCRIPTS_HOME}/magpie-run-execute scriptnokill ${MAGPIE_SCRIPTS_HOME}/magpie-run-job-hadoop-decommissionhdfsnodes &
        local scriptpid=$!
        Magpie_wait_script_sigusr2_on_job_timeout ${scriptpid}

        if [ $? -eq 0 ]
        then
            # Sets magpie_hdfs_stored_nodecount_path
            Magpie_get_hdfs_stored_nodecount_path

            rm -f ${magpie_hdfs_stored_nodecount_path}
            echo "${HADOOP_DECOMMISSION_HDFS_NODE_SIZE}" > ${magpie_hdfs_stored_nodecount_path}
        fi
    fi
}
 
Magpie_run_stop_hadoop () {
    if [ "${HADOOP_SETUP}" == "yes" ] && [ "${magpie_run_hadoop_should_be_torndown}" == "1" ]
    then
        if [ ${HADOOP_MODE} != "setuponly" ]
        then
            cd ${HADOOP_HOME}
            
            echo "Stopping hadoop"
            
            # Make variables unspecified for shutdown
            Magpie_make_all_local_dirs_unspecified

            if [ "${HADOOP_SETUP_TYPE}" == "MR1" ]
            then
                ${hadoopsetupscriptprefix}/stop-mapred.sh
                ${hadoopsetupscriptprefix}/stop-jobhistoryserver.sh
            fi
            
            if [ "${HADOOP_SETUP_TYPE}" == "MR2" ]
            then
                ${hadoopsetupscriptprefix}/stop-yarn.sh
                ${hadoopsetupscriptprefix}/mr-jobhistory-daemon.sh stop historyserver
            fi

            # Make variables specific now within Magpie
            Magpie_make_all_local_dirs_node_specific

            if Magpie_hadoop_filesystem_mode_is_hdfs_type
            then
                if [ "${magpie_run_hadoop_setup_successful}" == "1" ]
                then
                    echo "Saving namespace before shutting down hdfs ..."

                    if Magpie_hdfs_federation_enabled
                    then
                        for i in `seq 1 ${HDFS_FEDERATION_NAMENODE_COUNT}`
                        do
                            # First namenode is based on master
                            if [ "${i}" == "1" ]
                            then
                                federationnamenodehost="${HADOOP_MASTER_NODE}"
                            else
                                numline=`expr ${i} - 1`
                                federationnamenodehost=`sed -n "${numline}p" ${HADOOP_CONF_DIR}/namenode_hdfs_federation`
                            fi
                            
                            command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${default_hadoop_hdfs_namenode_address} -safemode enter"
                            echo "Running $command" >&2
                            $command
                            
                            command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${default_hadoop_hdfs_namenode_address} -saveNamespace"
                            echo "Running $command" >&2
                            $command
                            
                            command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -fs hdfs://${federationnamenodehost}:${default_hadoop_hdfs_namenode_address} -safemode leave"
                            echo "Running $command" >&2
                            $command
                        done
                    else
                        command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode enter"
                        echo "Running $command" >&2
                        $command
                        
                        command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -saveNamespace"
                        echo "Running $command" >&2
                        $command
                        
                        command="${hadoopcmdprefix}/${dfsadminscript} dfsadmin -safemode leave"
                        echo "Running $command" >&2
                        $command
                    fi
                fi

                # Make variables unspecified for shutdown
                Magpie_make_all_local_dirs_unspecified

                ${hadoopsetupscriptprefix}/stop-dfs.sh 

                # Make variables specific now within Magpie
                Magpie_make_all_local_dirs_node_specific
            fi
        fi
    fi
    magpie_run_hadoop_teardown_complete=1
}
