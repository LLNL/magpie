Instructions For Using Zeppelin
------------------------------

0) If necessary, download your favorite version of Zeppelin off of Apache
   and install it into a location where it's accessible on all cluster
   nodes.  Usually this is on a NFS home directory.

   See below in 'Zeppelin Patching' about patches that may be necessary
   for Zeppelin depending on your environment and Zeppelin version.

   See 'Convenience Scripts' in README about
   misc/magpie-apache-download-and-setup.sh, which may make the
   downloading and patching easier.

1) Select an appropriate submission script for running your job.  You
   can find them in the directory submission-scripts/, with Slurm
   Sbatch scripts using srun in script-sbatch-srun, Moab Msub+Slurm
   scripts using srun in script-msub-slurm-srun, Moab Msub+Torque
   scripts using pdsh in script-msub-torque-pdsh, and LSF scripts
   using mpirun in script-lsf-mpirun.

   You'll likely want to start with the base script
   (e.g. magpie.sbatch-srun) for your scheduler/resource manager 
   which contains all configuration options.

2) Setup your job essentials at the top of the submission script.  As
   an example, the following are the essentials for running with Moab.

   #MSUB -l nodes : Set how many nodes you want in your job

   #MSUB -l walltime : Set the time for this job to run

   #MSUB -l partition : Set the job partition

   #MSUB -q <my batch queue> : Set to batch queue

   MOAB_JOBNAME : Set your job name.

   MAGPIE_SCRIPTS_HOME : Set where your scripts are

   MAGPIE_LOCAL_DIR : For scratch space files

   MAGPIE_JOB_TYPE : This should be set to 'zeppelin'

   JAVA_HOME : B/c you need to ...

3) Setup the essentials for Zeppelin.

   ZEPPELIN_SETUP : Set to yes

   ZEPPELIN_VERSION : Set appropriately.

   ZEPPELIN_HOME : Where your Zeppelin code is.  Typically in an NFS mount.

   ZEPPELIN_LOCAL_DIR : A small place for conf files and log files local to
   each node.  Typically /tmp directory.

4) Select how your job will run by setting ZEPPELIN_MODE.  
   You may want to run with 'server' mode to play around and figure things
   out.  In the job output you will see output similar to the following:

   * To access Zeppelin's web interface, you'll want to navigate your browser to:
   *     http://some-node:18080 

   If you point your browser to this node and port you can access the Zeppelin
   Notebook/Interpreter. From here you can create notebooks and run code.

   A quick example once you navigate to the webpage:
   - Click the link "Create new note"
   - Click "Create Note"
   - In the first paragraph add the following:
   """
    %spark
    val count = sc.parallelize(1 to 1000).map{i =>
      val x = Math.random()
      val y = Math.random()
      if (x*x + y*y < 1) 1 else 0
    }.reduce(_ + _)
    println("Pi is roughly " + 4.0 * count / 1000)
   """
   - Click the 'play' button in the top right corner of the paragraph.

   This should display a value around 3.14 if successful.

   See "Exported Environment Variables" in README for information on
   common exported environment variables that may be useful in
   scripts.

   See below in "Zeppelin Exported Environment Variables", for
   information on Zeppelin specific exported environment variables that
   may be useful in scripts.

5) Zeppelin requires Spark, so ensure Spark is configured and also in
   your submission script.  See README.spark for setup instructions.

6) Submit your job into the cluster by running "sbatch -k
   ./magpie.sbatchfile" for Slurm, "msub ./magpie.msubfile" for
   Moab, or "bsub < .magpie.lsffile" for LSF.
   Add any other options you see fit.

7) Look at your job output file to see your output.  There will also
   be some notes/instructions/tips in the output file for viewing the
   status of your job in a web browser, environment variables you wish
   to set if interacting with it, etc.

   See "General Advanced Usage" in README for additional tips.

Zeppelin Exported Environment Variables
---------------------------------------

The following environment variables are exported when your job is run
and may be useful in scripts in your run or in pre/post run scripts.

ZEPPELIN_MASTER_NODE : the master node running Zeppelin

ZEPPELIN_CONF_DIR : the directory that Zeppelin configuration files local
                   to the node are stored

ZEPPELIN_LOG_DIR : the directory Zeppelin log files are stored

ZEPPELIN_SCALA_PATH : the path to the version of Scala needed

ZEPPELIN_SPARK_SUBMIT_OPTIONS : options for when Zeppelin submits jobs

See "Spark Exported Environment Variables" in README.spark,
for Spark environment variables that may be useful.

See "Zookeeper Exported Environment Variables" in README.zookeeper,
for Zookeeper environment variables that may be useful.

Zeppelin Patching
----------------
There are currently no patches needed for Zeppelin.

Zeppelin Testing
---------------

Zeppelin was manually tested while running Hadoop 2.7.1 MR2, 
Hbase 1.1.3, Phoenix 4.6.0, Spark 1.5.1, Kafka 2.11-0.9.0.0 
and Zookeeper-3.4.6. 
